# ğŸ–¼ï¸ Distributed Image Processing Pipeline with Kafka

A complete distributed system for processing large images using Apache Kafka, featuring parallel processing, real-time monitoring, and a web interface.

## ğŸ¯ Features

- âœ… **Web UI** - Upload images and view results via Flask web interface
- âœ… **Distributed Processing** - Multiple workers process image tiles in parallel
- âœ… **Kafka Integration** - Reliable message passing for task distribution
- âœ… **Real-time Monitoring** - Dashboard showing worker status and job progress
- âœ… **Metadata Tracking** - SQLite database for job and worker tracking
- âœ… **Heartbeat System** - Automatic worker health monitoring
- âœ… **Progress Tracking** - Real-time progress updates for each job

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚  (Web Browser)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Flask App   â”‚  (Upload & Dashboard)
â”‚ + Master    â”‚  (Image splitting & reconstruction)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Kafka    â”‚  (Message Broker)
â”‚   Broker    â”‚  - tasks topic
â”‚             â”‚  - results topic
â”‚             â”‚  - heartbeats topic
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Worker 1   â”‚  Worker 2   â”‚
â”‚ (Process)   â”‚ (Process)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‹ Prerequisites

- Python 3.8+
- Apache Kafka (running on broker)
- ZeroTier or network connectivity to Kafka broker

## ğŸš€ Installation

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Configure Kafka Broker IP

Update the `BROKER_IP` in the following files:
- `master_api.py`
- `consumer.py`
- `producer.py`
- `worker_main.py`
- `worker_heartbeat.py`

```python
BROKER_IP = "YOUR_KAFKA_IP:9092"  # e.g., "172.24.52.130:9092"
```

### 3. Initialize Database

```bash
python database.py
```

## ğŸ® Usage

### Starting the System

#### 1. Start the Web UI & Master Node

```bash
python app.py
```

Access the application at:
- **Upload Page**: http://localhost:5000
- **Dashboard**: http://localhost:5000/dashboard

#### 2. Start Worker Nodes

Open separate terminals for each worker:

**Worker 1:**
```bash
python worker_main.py
```

**Worker 2:**
Edit `worker_main.py` to set `WORKER_ID = "worker-2"`, then:
```bash
python worker_main.py
```

### Using the Web Interface

1. **Upload Image**
   - Go to http://localhost:5000
   - Click or drag-and-drop an image (min 1024x1024)
   - Click "Process Image"

2. **Monitor Progress**
   - View real-time progress on the upload page
   - Check detailed metrics on the dashboard

3. **Download Results**
   - Click "Download" button when processing completes
   - Processed image will be downloaded automatically

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ app.py                 # Flask web application
â”œâ”€â”€ master_api.py          # Master node logic (task distribution & collection)
â”œâ”€â”€ database.py            # SQLite database operations
â”œâ”€â”€ worker_main.py         # Worker node implementation
â”œâ”€â”€ consumer.py            # Kafka consumer utilities
â”œâ”€â”€ producer.py            # Kafka producer utilities
â”œâ”€â”€ processor.py           # Image processing logic (blur)
â”œâ”€â”€ worker_heartbeat.py    # Standalone heartbeat sender
â”œâ”€â”€ master_node.py         # Original standalone master (legacy)
â”œâ”€â”€ templates/
â”‚   â”œâ”€â”€ index.html        # Upload page UI
â”‚   â””â”€â”€ dashboard.html    # Monitoring dashboard UI
â”œâ”€â”€ uploads/              # Uploaded images
â”œâ”€â”€ outputs/              # Processed images
â””â”€â”€ requirements.txt      # Python dependencies
```

## ğŸ—„ï¸ Database Schema

### Jobs Table
Tracks image processing jobs with status, progress, and metadata.

### Tiles Table
Tracks individual tile processing status.

### Workers Table
Stores worker heartbeats and task counts.

## ğŸ”§ Configuration

### Tile Size
Default: 512x512 pixels. Can be adjusted in `master_api.py`:
```python
TILE_SIZE = 512
```

### Processing Timeout
Default: 120 seconds. Adjust in `master_api.py`:
```python
WAIT_TIMEOUT = 120
```

### Heartbeat Interval
Default: 5 seconds. Adjust in `worker_main.py`:
```python
HEARTBEAT_INTERVAL = 5
```

## ğŸ“Š API Endpoints

### Jobs
- `POST /api/upload` - Upload and process image
- `GET /api/jobs` - List all jobs
- `GET /api/jobs/<job_id>/status` - Get job progress
- `GET /api/jobs/<job_id>/result` - Download processed image

### Workers
- `GET /api/workers` - List all workers
- `GET /api/workers/active` - List active workers

### Stats
- `GET /api/stats` - Get system statistics

## ğŸ¨ Image Processing

Currently implements **Gaussian Blur** with a 51x51 kernel. To change processing:

Edit `processor.py`:
```python
def process_blur(b64_tile):
    # Your custom processing here
    # Example: Grayscale conversion
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
```

## ğŸ› Troubleshooting

### Kafka Connection Issues
- Verify Kafka broker is running
- Check `BROKER_IP` configuration
- Test network connectivity: `telnet <KAFKA_IP> 9092`

### Workers Not Processing
- Check worker console for errors
- Verify Kafka topics exist: `tasks`, `results`, `heartbeats`
- Ensure consumer group is properly configured

### Database Errors
- Delete `image_processing.db` and run `python database.py`
- Check file permissions

## ğŸ“ˆ Performance Tips

1. **More Workers**: Run multiple worker instances for faster processing
2. **Smaller Tiles**: Reduce `TILE_SIZE` for better parallelization (but more overhead)
3. **Kafka Partitions**: Configure Kafka with partitions matching worker count
4. **Network**: Use local network or high-speed connection for large images

## ğŸ“ Project Requirements Checklist

- âœ… Master node with tiling and reconstruction
- âœ… Worker nodes with Kafka integration
- âœ… Kafka broker with 3 topics
- âœ… Flask web UI with upload
- âœ… Real-time monitoring dashboard
- âœ… SQLite metadata storage
- âœ… Heartbeat monitoring
- âœ… Progress tracking
- âœ… Job status display

## ğŸ“ License

This project is for educational purposes (PES University - Big Data Course).

## ğŸ‘¥ Contributors

- Your Team Members Here

## ğŸ™ Acknowledgments

- Apache Kafka
- Flask Framework
- OpenCV Library
- PES University BD Course
